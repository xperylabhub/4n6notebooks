{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parsing iOS decrypted Signal DB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import  plistlib\n",
    "import json\n",
    "import os\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import zipfile\n",
    "import tarfile\n",
    "from chat_rendering import chat_HTML, render_chat, includes, CSS\n",
    "from base64 import b64encode, b64decode\n",
    "from Crypto.Cipher import AES\n",
    "from struct import unpack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Here goes the paths of necessary files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iOS file system extraction - only Zip archive currently supported\n",
    "#archive = '../mnt/test_snapchat/2020_03/dumps/7761_EX_INL_249_20_PALP_ZY_UN_01_files_full.zip'\n",
    "#archive = '/home/mat/mnt2/test_snapchat/FullFileSystem.1.dar'\n",
    "#archive = '../mnt/expertises/2020_03/dumps/7761_EX_INL_249_20_PALPATION_ON_UN_01_mnt2.tar'\n",
    "archive = '/home/mat/mnt2/images/2021_04/BA_DEUX/UFED Apple iPhone 6s Plus (A1687) 2021_03_29 (001)/AdvancedLogical Full File System (checkm8) 01/FullFileSystem.1.dar'\n",
    "\n",
    "# Path where to write results\n",
    "#out_path = '/home/mat/mnt2/analyses/2020_03/PALP_ZY_UN/snapchat'\n",
    "out_path = '/home/mat/mnt2/analyses/2021_04/BA_DEUX/signal'\n",
    "os.makedirs(out_path, exist_ok=True)\n",
    "\n",
    "# Path of encrypted archive in the archive\n",
    "signal_enc_db_name = 'signal.sqlite'\n",
    "\n",
    "# Path of decrypted keychain plist of the phone (on your FS)\n",
    "#keychain_plist_path = '../mnt/expertises/2020_03/dumps/7761_EX_INL_249_20_PALP_ZY_UN_01_keychain.plist'\n",
    "keychain_plist_path = '/home/mat/mnt2/images/2021_04/BA_DEUX/UFED Apple iPhone 6s Plus (A1687) 2021_03_29 (001)/AdvancedLogical Full File System (checkm8) 01/KeychainDump/keychain_decrypted.plist'\n",
    "\n",
    "#constants\n",
    "TAR = \"tar\"\n",
    "\n",
    "ZIP = \"zip\"\n",
    "\n",
    "DAR = \"dar\"\n",
    "\n",
    "os.makedirs(out_path, exist_ok = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decrypting DB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Extracting key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'\\xe0\\x83\\xd2d\\x9f\\xb7\\xadm\\xd6\\n\\x9eb\\xaeE\\xee\\xb1\\x19Hi\\xd4\\xc7\\xa468<\\x07\\xaf(\\x93\\xf9\\xa6\\x1f\\xcc\\x80M\\xc9J\\xfc\\x87\\x00,\\xd6Z\\xd0X\\xdb\\xd1-'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(keychain_plist_path,'rb') as f :\n",
    "    plist = plistlib.load(f)\n",
    "    \n",
    "def getSignalKeyFromKeychain():\n",
    "    if type(plist) == list:\n",
    "        for dd in plist:\n",
    "            if type(dd) == dict:        \n",
    "                if 'acct' in dd:\n",
    "                    if 'GRDBDatabaseCipherKeySpec' in str(dd['acct']) or str(b64encode(b'GRDBDatabaseCipherKeySpec')) in str(dd['acct']):\n",
    "                        return dd['v_Data']\n",
    "    else:\n",
    "        for d in plist:\n",
    "            for dd in plist[d]:\n",
    "                if type(dd) == dict:        \n",
    "                    if 'acct' in dd:\n",
    "                        if 'GRDBDatabaseCipherKeySpec' in str(dd['acct']) or str(b64encode(b'GRDBDatabaseCipherKeySpec')) in str(dd['acct']):\n",
    "                            return dd['v_Data']\n",
    "    return None\n",
    "\n",
    "key = getSignalKeyFromKeychain()\n",
    "key\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Loading archive file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if archive.endswith('zip'):\n",
    "    archive_type = ZIP\n",
    "    arc_handle = zipfile.ZipFile(archive)\n",
    "    files = arc_handle.namelist()\n",
    "elif archive.endswith('tar') or archive.endswith('gz'):\n",
    "    archive_type = TAR\n",
    "    arc_handle = tarfile.TarFile(archive)\n",
    "    files = arc_handle.getnames()\n",
    "    \n",
    "elif archive.endswith('dar'):\n",
    "    archive_type = DAR\n",
    "    import subprocess\n",
    "    list_dar = subprocess.run([\n",
    "                \"dar\",\n",
    "                \"-l\",\n",
    "                archive[:-6]\n",
    "            ],\n",
    "            shell=False,\n",
    "            capture_output=True,\n",
    "            )\n",
    "    \n",
    "    file_list = BytesIO(list_dar.stdout).readlines()\n",
    "    files = []\n",
    "    for l in file_list:\n",
    "        if l.startswith(b'['):\n",
    "            files.append(l.split(b'\\t')[-1].decode('utf8').strip())\n",
    "    \n",
    "else:\n",
    "    print(\"ERROR : file not supported\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if archive_type == DAR:\n",
    "    encrypteddb = [f for f in files if signal_enc_db_name in f][0]\n",
    "    extract_file = subprocess.run([\n",
    "                    \"dar\",\n",
    "                    \"-x\",\n",
    "                    archive[:-6],\n",
    "                    \"-g\",\n",
    "                    encrypteddb,\n",
    "                    \"-R\",\n",
    "                    out_path,\n",
    "                    \"-Oignore-owner\"\n",
    "                ],\n",
    "                shell=False,\n",
    "                capture_output=True,\n",
    "                )\n",
    "    enc_db_size = os.path.getsize(os.path.join(out_path,encrypteddb))\n",
    "    tmp = open(os.path.join(out_path,encrypteddb), 'rb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_path = [f for f in files if f.endswith(signal_enc_db_name) and not '_' in os.path.basename(f)][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Extracting DB to temp file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if archive_type == ZIP:\n",
    "    db_path = [f for f in files if f.endswith(signal_enc_db_name) and not '_' in os.path.basename(f)][0]\n",
    "\n",
    "    tmp = tempfile.NamedTemporaryFile()\n",
    "    tmp.write(arc_handle.open(db_path).read())\n",
    "    enc_db_size = arc_handle.getinfo(db_path).file_size\n",
    "    \n",
    "elif archive_type == TAR:\n",
    "    db_path = [f for f in files if f.endswith(signal_enc_db_name) and not '_' in os.path.basename(f)][0]\n",
    "\n",
    "    tmp = tempfile.NamedTemporaryFile()\n",
    "    tmp.write(arc_handle.extractfile(db_path).read())\n",
    "    enc_db_size = arc_handle.getmember(db_path).size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Decrypting DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp.seek(0)\n",
    "signal_header_size = 0x20\n",
    "default_page_size=0x1000\n",
    "page_size = default_page_size\n",
    "header_size = signal_header_size\n",
    "header = tmp.read(header_size)\n",
    "salt_sz = 0x10\n",
    "hmac_sz = 0x40\n",
    "reserved_sz = salt_sz + hmac_sz\n",
    "max_page = int(enc_db_size / default_page_size)\n",
    "\n",
    "def decrypt_page(page_offset):\n",
    "    if page_offset == 0:\n",
    "        page_data = tmp.read(page_size - header_size)\n",
    "    else:\n",
    "        page_data = tmp.read(page_size)\n",
    "    \n",
    "    iv = page_data[-reserved_sz:-reserved_sz+salt_sz]\n",
    "\n",
    "    decryption_suite = AES.new(key[:32], AES.MODE_CBC, iv)\n",
    "    plain_text = decryption_suite.decrypt(page_data[:-reserved_sz])\n",
    "    \n",
    "    return plain_text\n",
    "\n",
    "with open(os.path.join(out_path,'signal-decrypted.sqlite'),'wb') as decrypted:\n",
    "    decrypted.write(header)\n",
    "    \n",
    "    for page in range(0,max_page):\n",
    "        decrypted.write(decrypt_page(page))\n",
    "        decrypted.write(b'\\x00'*reserved_sz)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Decrypting WAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "wal_signal_enc_db_name = signal_enc_db_name+'-'+'wal'\n",
    "\n",
    "if archive_type == DAR:\n",
    "    filepath = [f for f in files if wal_signal_enc_db_name in f][0]\n",
    "    enc_db_size = os.path.getsize(filepath)\n",
    "    tmp = open(filepath, 'rb')\n",
    "    \n",
    "elif archive_type == ZIP:\n",
    "    db_path = [f for f in files if f.endswith(wal_signal_enc_db_name) and not '_' in os.path.basename(f)][0]\n",
    "\n",
    "    tmp = tempfile.NamedTemporaryFile()\n",
    "    tmp.write(arc_handle.open(db_path).read())\n",
    "    enc_db_size = arc_handle.getinfo(db_path).file_size\n",
    "    \n",
    "elif archive_type == TAR:\n",
    "    db_path = [f for f in files if f.endswith(wal_signal_enc_db_name) and not '_' in os.path.basename(f)][0]\n",
    "\n",
    "    tmp = tempfile.NamedTemporaryFile()\n",
    "    tmp.write(arc_handle.extractfile(db_path).read())\n",
    "    enc_db_size = arc_handle.getmember(db_path).size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp.seek(0)\n",
    "wal_header_size = 32\n",
    "wal_page_header_size = 24\n",
    "signal_header_size = 0x20\n",
    "wal_header = tmp.read(wal_header_size)\n",
    "page_size = unpack('>I',wal_header[8:12])[0]\n",
    "salt_sz = 0x10\n",
    "hmac_sz = 0x40\n",
    "reserved_sz = salt_sz + hmac_sz\n",
    "max_page = int((enc_db_size - wal_header_size) / (page_size + wal_page_header_size))\n",
    "\n",
    "def decrypt_page(page_offset):\n",
    "    page_header = tmp.read(wal_page_header_size)\n",
    "    page_number = unpack('>I',page_header[:4])[0]\n",
    "    plain_text = b''\n",
    "    if page_number == 0:\n",
    "        plain_text += tmp.read(signal_header_size)\n",
    "        page_data = tmp.read(page_size - signal_header_size)\n",
    "    else:\n",
    "        page_data = tmp.read(page_size)\n",
    "    \n",
    "    iv = page_data[-reserved_sz:-reserved_sz+salt_sz]\n",
    "\n",
    "    decryption_suite = AES.new(key[:32], AES.MODE_CBC, iv)\n",
    "    plain_text += decryption_suite.decrypt(page_data[:-reserved_sz])\n",
    "    \n",
    "    return plain_text\n",
    "\n",
    "with open(os.path.join(out_path,'signal-decrypted-wal.sqlite'),'wb') as decrypted:\n",
    "    decrypted.write(header)\n",
    "    \n",
    "    for page in range(0,max_page):\n",
    "        decrypted.write(decrypt_page(page))\n",
    "        decrypted.write(b'\\x00'*reserved_sz)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use SQL Carver to extract data from WAL file\n",
    "\n",
    "#TODO : implement SQL Carver :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parsing Data\n",
    "#### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "recordTypes = {56: 'baseModel',\n",
    " 55: 'experienceUpgrade',\n",
    " 63: 'incomingGroupsV2MessageJob',\n",
    " 24: 'installedSticker',\n",
    " 29: 'knownStickerPack',\n",
    " 40: '_100RemoveTSRecipientsMigration',\n",
    " 43: '_101ExistingUsersBlockOnIdentityChange',\n",
    " 47: '_102MoveLoggingPreferenceToUserDefaults',\n",
    " 42: '_103EnableVideoCalling',\n",
    " 45: '_104CreateRecipientIdentities',\n",
    " 44: '_105AttachmentFilePaths',\n",
    " 50: '_107LegacySounds',\n",
    " 48: '_108CallLoggingPreference',\n",
    " 51: '_109OutgoingMessageState',\n",
    " 25: 'addToContactsOfferMessage',\n",
    " 7: 'addToProfileWhitelistOfferMessage',\n",
    " 32: 'backupFragment',\n",
    " 58: 'broadcastMediaMessageJobRecord',\n",
    " 22: 'contactOffersInteraction',\n",
    " 57: 'contactQuery',\n",
    " 46: 'databaseMigration',\n",
    " 33: 'device',\n",
    " 28: 'disappearingConfigurationUpdateInfoMessage',\n",
    " 39: 'disappearingMessagesConfiguration',\n",
    " 61: 'incomingContactSyncJobRecord',\n",
    " 60: 'incomingGroupSyncJobRecord',\n",
    " 36: 'linkedDeviceReadReceipt',\n",
    " 15: 'messageContentJob',\n",
    " 8: 'messageDecryptJob',\n",
    " 62: 'reaction',\n",
    " 38: 'recipientIdentity',\n",
    " 49: 'resaveCollectionDBMigration',\n",
    " 52: 'sessionResetJobRecord',\n",
    " 5: 'unknownContactBlockOfferMessage',\n",
    " 37: 'unknownDBObject',\n",
    " 54: 'unknownProtocolVersionMessage',\n",
    " 41: 'userProfile',\n",
    " 13: 'verificationStateChangeMessage',\n",
    " 34: 'jobRecord',\n",
    " 53: 'messageDecryptJobRecord',\n",
    " 35: 'messageSenderJobRecord',\n",
    " 30: 'signalAccount',\n",
    " 31: 'signalRecipient',\n",
    " 14: 'stickerPack',\n",
    " 6: 'attachment',\n",
    " 3: 'attachmentPointer',\n",
    " 18: 'attachmentStream',\n",
    " 20: 'call',\n",
    " 27: 'contactThread',\n",
    " 9: 'errorMessage',\n",
    " 26: 'groupThread',\n",
    " 19: 'incomingMessage',\n",
    " 10: 'infoMessage',\n",
    " 16: 'interaction',\n",
    " 17: 'invalidIdentityKeyErrorMessage',\n",
    " 1: 'invalidIdentityKeyReceivingErrorMessage',\n",
    " 23: 'invalidIdentityKeySendingErrorMessage',\n",
    " 64: 'mention',\n",
    " 11: 'message',\n",
    " 21: 'outgoingMessage',\n",
    " 12: 'recipientReadReceipt',\n",
    " 2: 'thread',\n",
    " 4: 'unreadIndicatorInteraction',\n",
    " 59: 'testModel'\n",
    "}\n",
    "\n",
    "mimeTypeIcon = {\n",
    "    \"image\":\"ðŸ“·\",\n",
    "    \"audio\":\"ðŸŽ§\",\n",
    "    \"video\":\"ðŸŽ¥\",\n",
    "    \"animated\":\"ðŸŽ¡\",\n",
    "    \"other\":\"ðŸ“Ž\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#signal_root = '/private/var/mobile/Containers/Shared/AppGroup/DA91D9C6-9E47-4B14-8468-D347C98D599C/Attachments'\n",
    "signal_root = '/'.join([db_path.split('/grdb')[0],'Attachments'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Starting to extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = sqlite3.connect(os.path.join(out_path,'signal-decrypted.sqlite'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "threads = pd.read_sql_query(\"\"\"\n",
    "SELECT \n",
    "    t.contactPhoneNumber, \n",
    "    t.uniqueId as uniqueId_T, \n",
    "    t.lastInteractionRowId, \n",
    "    t.contactUUID,\n",
    "    i.uniqueThreadId,\n",
    "    i.attachmentIds,\n",
    "    i.timestamp,\n",
    "    i.receivedAtTimestamp,\n",
    "    i.body,\n",
    "    i.id,\n",
    "    i.recordType,\n",
    "    i.authorUUID,\n",
    "    i.sender,\n",
    "    i.configurationDurationSeconds,\n",
    "    u.avatarUrlPath,\n",
    "    u.profileName\n",
    "    \n",
    "FROM \n",
    "    model_TSInteraction i\n",
    "    LEFT OUTER JOIN model_TSThread t\n",
    "        ON i.uniqueThreadId = t.uniqueId\n",
    "    LEFT OUTER JOIN model_OWSUserProfile u\n",
    "        on t.contactPhoneNumber = u.recipientPhoneNumber\n",
    "    \n",
    "\"\"\", db)\n",
    "\n",
    "attachments = pd.read_sql_query(\"\"\"\n",
    "SELECT\n",
    "    uniqueId,\n",
    "    caption,\n",
    "    contentType,\n",
    "    sourceFilename,\n",
    "    localRelativeFilePath,\n",
    "    isValidImageCached OR isValidVideoCached as cached\n",
    "FROM\n",
    "    model_TSAttachment\n",
    "\"\"\", db)\n",
    "db.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>contactPhoneNumber</th>\n",
       "      <th>uniqueId_T</th>\n",
       "      <th>lastInteractionRowId</th>\n",
       "      <th>contactUUID</th>\n",
       "      <th>uniqueThreadId</th>\n",
       "      <th>attachmentIds</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>receivedAtTimestamp</th>\n",
       "      <th>body</th>\n",
       "      <th>id</th>\n",
       "      <th>recordType</th>\n",
       "      <th>authorUUID</th>\n",
       "      <th>sender</th>\n",
       "      <th>configurationDurationSeconds</th>\n",
       "      <th>avatarUrlPath</th>\n",
       "      <th>profileName</th>\n",
       "      <th>parsedAttachmentIds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [contactPhoneNumber, uniqueId_T, lastInteractionRowId, contactUUID, uniqueThreadId, attachmentIds, timestamp, receivedAtTimestamp, body, id, recordType, authorUUID, sender, configurationDurationSeconds, avatarUrlPath, profileName, parsedAttachmentIds]\n",
       "Index: []"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "parsedAttachmentIds field contains the attachements of a message in a binary plist format.\n",
    "Currrently only supporting one attachment per message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parsePlist(record):\n",
    "    try:\n",
    "        d = plistlib.loads(record[\"attachmentIds\"], fmt = plistlib.FMT_BINARY)\n",
    "        if d:\n",
    "            if d['$objects'][1]['NS.objects']:\n",
    "                return d['$objects'][2]\n",
    "        return None\n",
    "    except:\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Formatting the DF and extracting attachment to pass to chat_render function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "You are trying to merge on float64 and object columns. If you wish to proceed you should use pd.concat",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-f8e093fc7a96>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mthreads\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"parsedAttachmentIds\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mthreads\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mparsePlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mthreads_Att\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mthreads\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattachments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleft_on\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"parsedAttachmentIds\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright_on\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"uniqueId\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"left\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mthreads_Att\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"recordType\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mthreads\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mrecordTypes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"recordType\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mthreads_Att\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"data-name\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mthreads_Att\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"profileName\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"profileName\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"contactPhoneNumber\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mmerge\u001b[0;34m(self, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m   8193\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmerge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 8195\u001b[0;31m         return merge(\n\u001b[0m\u001b[1;32m   8196\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8197\u001b[0m             \u001b[0mright\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36mmerge\u001b[0;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0mvalidate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m ) -> \"DataFrame\":\n\u001b[0;32m---> 74\u001b[0;31m     op = _MergeOperation(\n\u001b[0m\u001b[1;32m     75\u001b[0m         \u001b[0mleft\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0mright\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, left, right, how, on, left_on, right_on, axis, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m    670\u001b[0m         \u001b[0;31m# validate the merge keys dtypes. We may need to coerce\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m         \u001b[0;31m# to avoid incompatible dtypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 672\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_coerce_merge_keys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    673\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m         \u001b[0;31m# If argument passed to validate,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m_maybe_coerce_merge_keys\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1191\u001b[0m                     \u001b[0minferred_right\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstring_types\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0minferred_left\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstring_types\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m                 ):\n\u001b[0;32m-> 1193\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1195\u001b[0m             \u001b[0;31m# datetimelikes must match exactly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: You are trying to merge on float64 and object columns. If you wish to proceed you should use pd.concat"
     ]
    }
   ],
   "source": [
    "threads[\"parsedAttachmentIds\"] = threads.apply(lambda record: parsePlist(record),axis=1)\n",
    "threads_Att = threads.merge(attachments, left_on=\"parsedAttachmentIds\", right_on=\"uniqueId\", how=\"left\")\n",
    "\n",
    "threads_Att[\"recordType\"] = threads.apply(lambda record: recordTypes[record[\"recordType\"]],axis=1)\n",
    "threads_Att[\"data-name\"] = threads_Att.apply(lambda row: row[\"profileName\"] if row[\"profileName\"] is not None else row[\"contactPhoneNumber\"], axis=1)\n",
    "threads_Att[\"from_me\"] = threads_Att.apply(lambda row: 1 if row[\"recordType\"] == \"outgoingMessage\" else 0, axis=1)\n",
    "threads_Att[\"body\"] = threads_Att.apply(lambda row: row[\"recordType\"] if row[\"recordType\"] not in [\"incomingMessage\",\"outgoingMessage\"] else row[\"body\"], axis=1)\n",
    "threads_Att[\"data-time\"] = pd.to_datetime(threads_Att[\"timestamp\"], unit='ms')\n",
    "threads_Att = threads_Att.rename(columns={\"body\": \"message\",\"contentType\":\"content-type\"})\n",
    "\n",
    "#export df to excel\n",
    "threads_Att.to_excel(os.path.join(out_path,'signal.xlsx'), sheet_name=\"signal\", columns=[\"data-time\",\"profileName\",\"contactPhoneNumber\",\"recordType\",\"message\",\"content-type\"], index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(os.path.join(out_path,'att'), exist_ok=True)\n",
    "\n",
    "def copyAttachments(rec):\n",
    "    rec['file-path'] = None\n",
    "    if type(rec[\"localRelativeFilePath\"]) == str:\n",
    "        outfilename = os.path.join(out_path,'att',rec[\"localRelativeFilePath\"].replace('/','_'))\n",
    "        file_in_archive = [f for f in files if rec[\"localRelativeFilePath\"] in f]\n",
    "        if len(file_in_archive) > 0:\n",
    "                if archive_type == DAR:\n",
    "                    extract_file = subprocess.run([\n",
    "                            \"dar\",\n",
    "                            \"-x\",\n",
    "                            archive[:-6],\n",
    "                            \"-g\",\n",
    "                            file_in_archive[0]\n",
    "                        ],\n",
    "                        shell=False,\n",
    "                        capture_output=True,\n",
    "                        )\n",
    "                    buf = open(file_in_archive[0], 'rb').read()\n",
    "                elif archive_type == ZIP:\n",
    "                    buf = arc_handle.open(file_in_archive[0],'r').read()\n",
    "                elif archive_type == TAR:\n",
    "                    buf = arc_handle.extractfile(file_in_archive[0]).read()\n",
    "                with open(outfilename,\"wb\") as out:\n",
    "                    out.write(buf)\n",
    "                rec['file-path'] = \"/\".join(outfilename.split('/')[3:])\n",
    "    return rec\n",
    "\n",
    "threads_Att = threads_Att.apply(lambda rec: copyAttachments(rec), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(out_path,'signal.html'),'w') as out:\n",
    "    out.write('<html><head>')\n",
    "    out.write(CSS)\n",
    "    out.write('</head>')\n",
    "    out.write(chat_HTML)\n",
    "    out.write(includes)\n",
    "    out.write(render_chat(threads_Att))\n",
    "    out.write('</body></html>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
